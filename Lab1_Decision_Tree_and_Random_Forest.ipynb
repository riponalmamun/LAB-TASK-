{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiPMtn8odCxvTvbLpmkKeW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihanewubd/CSE457/blob/main/Lab1_Decision_Tree_and_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 1 - Decision Tree"
      ],
      "metadata": {
        "id": "Qy2gZ3VdU_B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "id": "eSWGy7A0VDco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load iris data set"
      ],
      "metadata": {
        "id": "VTEU9WG_VLZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "# Convert the data to a pandas dataframe\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "# Add the target column\n",
        "df['species'] = iris.target\n",
        "# Check the shape and summary of the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "GQyDrHcYVKXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "5OUT0zk2ZC2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the dataset"
      ],
      "metadata": {
        "id": "uzbsq_RBWDSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the pairwise scatter plot of the features\n",
        "pd.plotting.scatter_matrix(df, figsize=(12, 8), diagonal='kde')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MVcqj7tcVr6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree using Numpy"
      ],
      "metadata": {
        "id": "SeTucqzHX1Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data\n",
        "y = iris.target\n",
        "# Split the data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SQrc7E1KoudA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, feature_names=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "        self.feature_names = feature_names\n",
        "\n",
        "    def entropy(self, y):\n",
        "        \"\"\"\n",
        "        Calculates the entropy of a dataset.\n",
        "\n",
        "        Args:\n",
        "          y: 1d array of labels\n",
        "\n",
        "        Returns:\n",
        "          float: entropy\n",
        "        \"\"\"\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    def information_gain(self, y, y1, y2):\n",
        "        \"\"\"\n",
        "        Calculates the information gain of a split.\n",
        "\n",
        "        Args:\n",
        "          y: 1d array of labels before split\n",
        "          y1: 1d array of labels in the left split\n",
        "          y2: 1d array of labels in the right split\n",
        "\n",
        "        Returns:\n",
        "          float: information gain\n",
        "        \"\"\"\n",
        "        p = len(y1) / len(y)\n",
        "        return self.entropy(y) - p * self.entropy(y1) - (1 - p) * self.entropy(y2)\n",
        "\n",
        "    def best_split(self, X, y):\n",
        "        \"\"\"\n",
        "        Finds the best split for a dataset.\n",
        "\n",
        "        Args:\n",
        "          X: 2d array of features\n",
        "          y: 1d array of labels\n",
        "\n",
        "        Returns:\n",
        "          tuple: (best_feature_index, best_threshold)\n",
        "        \"\"\"\n",
        "        best_gain = 0\n",
        "        best_feature_index = None\n",
        "        best_threshold = None\n",
        "        for feature_index in range(X.shape[1]):\n",
        "            #print(f\"feature_index: {feature_index}\")\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            #print(f\"thresholds: {thresholds}\")\n",
        "            for threshold in thresholds:\n",
        "                #print(f\"threshold: {threshold}\")\n",
        "                y1 = y[X[:, feature_index] <= threshold]\n",
        "                y2 = y[X[:, feature_index] > threshold]\n",
        "                #print(f\"y1: {y1}\")\n",
        "                #print(f\"y2: {y2}\")\n",
        "                gain = self.information_gain(y, y1, y2)\n",
        "                #print(f\"gain: {gain}\")\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature_index = feature_index\n",
        "                    best_threshold = threshold\n",
        "        return best_feature_index, best_threshold\n",
        "\n",
        "    def build_tree(self, X, y, depth=0):\n",
        "        \"\"\"\n",
        "        Builds a decision tree recursively.\n",
        "\n",
        "        Args:\n",
        "          X: 2d array of features\n",
        "          y: 1d array of labels\n",
        "          depth: current depth of the tree\n",
        "\n",
        "        Returns:\n",
        "          dict: decision tree\n",
        "        \"\"\"\n",
        "        if len(np.unique(y)) == 1:\n",
        "            return y[0]\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return np.argmax(np.bincount(y))\n",
        "        #print(f\"best split of {X} and {y}\")\n",
        "        feature_index, threshold = self.best_split(X, y)\n",
        "        left_indices = X[:, feature_index] <= threshold\n",
        "        right_indices = X[:, feature_index] > threshold\n",
        "        left_tree = self.build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self.build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        # Include feature name in the tree\n",
        "        feature_name = self.feature_names[feature_index] if self.feature_names else feature_index\n",
        "        return {\n",
        "            'feature_name': feature_name,\n",
        "            'feature_index': feature_index,\n",
        "            'threshold': threshold,\n",
        "            'left': left_tree,\n",
        "            'right': right_tree,\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fits the decision tree to the training data.\n",
        "\n",
        "        Args:\n",
        "          X: 2d array of features\n",
        "          y: 1d array of labels\n",
        "        \"\"\"\n",
        "        self.tree = self.build_tree(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the labels for a dataset.\n",
        "\n",
        "        Args:\n",
        "          X: 2d array of features\n",
        "\n",
        "        Returns:\n",
        "          1d array: predicted labels\n",
        "        \"\"\"\n",
        "        if len(X.shape) == 1:  # Handle single sample input\n",
        "            X = X.reshape(1, -1)\n",
        "        return np.array([self._predict(self.tree, x) for x in X])\n",
        "\n",
        "    def _predict(self, tree, x):\n",
        "        \"\"\"\n",
        "        Predicts the label for a single data point.\n",
        "\n",
        "        Args:\n",
        "          tree: decision tree\n",
        "          x: 1d array of features\n",
        "\n",
        "        Returns:\n",
        "          int: predicted label\n",
        "        \"\"\"\n",
        "        if isinstance(tree, dict):\n",
        "            if x[tree['feature_index']] <= tree['threshold']:\n",
        "                return self._predict(tree['left'], x)\n",
        "            else:\n",
        "                return self._predict(tree['right'], x)\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def visualize_tree(self, tree=None, dot=None, parent=None, edge_label=None):\n",
        "        \"\"\"\n",
        "        Visualizes the decision tree using graphviz.\n",
        "\n",
        "        Args:\n",
        "            tree: decision tree (root node)\n",
        "            dot: graphviz Digraph object\n",
        "            parent: parent node\n",
        "            edge_label: label for the edge connecting parent to current node\n",
        "        \"\"\"\n",
        "        if dot is None:\n",
        "            dot = Digraph()\n",
        "            dot.node(name='root', label=str(tree['feature_name']) + ' <= ' + str(round(tree['threshold'], 2)))\n",
        "            self.visualize_tree(tree['left'], dot, 'root', 'True')\n",
        "            self.visualize_tree(tree['right'], dot, 'root', 'False')\n",
        "            return dot\n",
        "\n",
        "        if isinstance(tree, dict):\n",
        "            node_id = str(id(tree))\n",
        "            node_label = str(tree['feature_name']) + ' <= ' + str(round(tree['threshold'], 2))\n",
        "            dot.node(name=node_id, label=node_label)\n",
        "            if parent is not None:\n",
        "                dot.edge(parent, node_id, label=edge_label)\n",
        "            self.visualize_tree(tree['left'], dot, node_id, 'True')\n",
        "            self.visualize_tree(tree['right'], dot, node_id, 'False')\n",
        "        else:\n",
        "            node_id = str(id(tree))\n",
        "            dot.node(name=node_id, label=str(tree), shape='box')  # Leaf nodes as boxes\n",
        "            if parent is not None:\n",
        "                dot.edge(parent, node_id, label=edge_label)\n",
        "\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names  # Get feature names\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the decision tree using the training data\n",
        "tree = DecisionTree(max_depth=6, feature_names=feature_names)  # Pass feature names\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the tree\n",
        "dot = tree.visualize_tree(tree.tree)\n",
        "dot.render('decision_tree', format='png')  # Save and display the tree\n",
        "from IPython.display import Image\n",
        "Image('decision_tree.png')\n",
        "# Predict the labels for the test data\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "ee4yozH2pVuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree using scikit-learn"
      ],
      "metadata": {
        "id": "FpcyP-sLYAAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into train and test. Fix the error in below code"
      ],
      "metadata": {
        "id": "ZEFhj9iqWKi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Define the features and the target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "# Split the data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "l-Y7HtocVyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test"
      ],
      "metadata": {
        "id": "LjUV3YIyWPsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier with gini criterion and maximum depth of 3\n",
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
        "# Fit the model on the train data\n",
        "dt.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "y_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "id": "wrFsvnuxV6o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the results"
      ],
      "metadata": {
        "id": "hUJhCCU2WTQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "# Calculate the accuracy, precision, recall, and f1-score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='macro')\n",
        "rec = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "# Print the results\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "print(f\"Precision: {prec:.2f}\")\n",
        "print(f\"Recall: {rec:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dT1Bxm5fWAr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the tree"
      ],
      "metadata": {
        "id": "yzEVfq8dWZiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(dt, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
        "plt.title('Decision Tree')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tLQx-fvoWa77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "rRwpT3vmX3Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "PXMDUOjRX73R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to a Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "print(df.head())\n",
        "# Describe the dataset\n",
        "#description = df.describe()\n",
        "#print(description)\n",
        "# Plot the pairwise scatter plot of the features\n",
        "#pd.plotting.scatter_matrix(df, figsize=(12, 8), diagonal='kde')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "n52zXqFyX-ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = data.target\n",
        "X = df.loc[:, df.columns != 'target']\n",
        "y = df.loc[:, 'target'].values"
      ],
      "metadata": {
        "id": "BOmvTY1ZYBJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ls77V_feYD40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "JV4hb2ISYF9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wCgI1TNyYHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "y5sMYje8YKl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "i96wUNDHYMub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "_ = tree.plot_tree(rf_classifier.estimators_[0], feature_names=X.columns, filled=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZSgwtceYO6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classify Mushroom Using Decision Tree and Random Forest.\n",
        "\n",
        "Dataset: https://archive.ics.uci.edu/dataset/73/mushroom\n",
        "\n",
        "Task details:\n",
        "\n",
        "2.   Perform Exploratory Data Analysis (EDA) on the dataset.\n",
        "3.   Evaluate and compare Random Forest tree accuracy for the following n_estimators values 1,50,100,150,200, and 250.\n",
        "4.   Evaluate and compare performance of Random Forest and Decision Tree.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1l2RL1D7YZAU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5fWfB7JYYt0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}